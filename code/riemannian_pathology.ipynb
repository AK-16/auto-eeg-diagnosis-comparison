{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"/home/gemeinl/code/brainfeatures/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyriemann.utils.mean import mean_covariance\n",
    "from pyriemann.tangentspace import TangentSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainfeatures.data_set.tuh_abnormal import TuhAbnormal\n",
    "from brainfeatures.utils.data_util import reject_windows_with_outliers, split_into_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TuhAbnormal(\"/home/gemeinl/data/pre_100_Hz_without_rejecting/train/\", n_recordings=200, extension=\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n for n in ds.file_names if \"00008184_s001_t001\" in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.file_names.index('/home/gemeinl/data/pre_100_Hz_without_rejecting/train/abnormal/01_tcp_ar/081/00008184/s001_2011_09_21/00008184_s001_t001.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainfeatures.decoding.decode import get_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_X_y(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), X[0].shape, len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [split_into_epochs(x.values, sfreq=100, epoch_duration_s=6) for x in X]\n",
    "epochs = [epoch[reject_windows_with_outliers(epoch) == False] for epoch in epochs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epochs), epochs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyriemann.estimation import Covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = Covariances()\n",
    "covs = [cov.fit_transform(subject) for subject in epochs] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_eval = TuhAbnormal(\"/home/gemeinl/data/pre_100_Hz_without_rejecting/eval/\", n_recordings=None, extension=\".h5\", subset=\"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_eval.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval, y_eval = get_X_y(ds_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_eval = [split_into_epochs(x.values, sfreq=100, epoch_duration_s=6) for x in X_eval]\n",
    "epochs_eval = [epoch[reject_windows_with_outliers(epoch) == False] for epoch in epochs_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epochs_eval), epochs_eval[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = Covariances()\n",
    "covs_eval = [cov.fit_transform(subject) for subject in epochs_eval] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.save(\"/home/gemeinl/data/covs/eval_covs.npy\", covs_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.save(\"/home/gemeinl/data/covs/eval_pathology_labels.npy\", y_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__load saved covariance matrices and labels from npy file instead of recomputing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs = np.load(\"/home/gemeinl/data/covs/train_covs_without_822.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load(\"/home/gemeinl/data/covs/train_pathology_labels_without_822.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(covs), covs[0].shape, len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove broken recording 822, 00008184_s001_t001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask = len(covs) * [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask[822] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "covs = [cov for i, cov in enumerate(covs) if mask[i] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = [y_ for i, y_ in enumerate(y) if mask[i] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(covs), covs[0].shape, len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for non-spd matrices and remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_SPD(covs):\n",
    "    good_ids = []\n",
    "    for i,cov in enumerate(covs):\n",
    "        try:\n",
    "            np.linalg.cholesky(cov)\n",
    "            good_ids.append(i)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return good_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_good_ids = [check_SPD(cov) for cov in covs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2716"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_good_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs = [cov[all_good_ids[i]] for i, cov in enumerate(covs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2716, (187, 21, 21), 2716)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(covs), covs[0].shape, len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_recs = 500\n",
    "covs = covs[:n_recs]\n",
    "y = y[:n_recs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(covs), covs[0].shape, len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_covs = CovsToMeanCov().fit_transform(covs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.save(\"/home/gemeinl/data/covs/mean_train_covs.npy\", mean_covs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__load saved mean covariance matrices and labels from npy file instead of recomputing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs = np.load(\"/home/gemeinl/data/covs/mean_train_covs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load(\"/home/gemeinl/data/covs/train_pathology_labels_without_822.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2716, 21, 21), (2716,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covs.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(covs) == len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimedTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, transformer):\n",
    "        self.transformer=transformer\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        t = time.time()\n",
    "        return_value = self.transformer.fit(X=X, y=y)\n",
    "        print(\"{} fitting time: {:.2f}s\".format(self.transformer.__repr__, time.time() - t))\n",
    "        return return_value\n",
    "    \n",
    "    def transform(self, X):\n",
    "        t = time.time()\n",
    "        return_value = self.transformer.transform(X=X)\n",
    "        print(\"{} transforming time: {:.2f}s\".format(self.transformer.__repr__, time.time() - t))\n",
    "        return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovsToMeanCov(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        mean_covs = np.array([mean_covariance(cov) for cov in X])\n",
    "        return mean_covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_acc(pred_df):\n",
    "    accs = []\n",
    "    for i, d in pred_df.groupby(\"id\"):\n",
    "        accs.append((d.y_pred == d.y_true).mean())\n",
    "    return np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=n_folds, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, n_ch, _ = covs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 10\n"
     ]
    }
   ],
   "source": [
    "kernel=\"rbf\"\n",
    "adaptation = False\n",
    "for C in [10]:\n",
    "    print(\"C\", C)\n",
    "    pipe = Pipeline([\n",
    "        #(\"mean_covs\", TimedTransformer(CovsToMeanCov())),\n",
    "        (\"ts\", TangentSpace(tsupdate=adaptation, metric=\"riemann\")),\n",
    "        #(\"scale\", StandardScaler()),\n",
    "        (\"clf\", SVC(kernel=kernel, C=C, probability=True, gamma=\"auto\"))\n",
    "    ])\n",
    "\n",
    "    train_preds, test_preds, train_probas, test_probas = pd.DataFrame(),pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "    for fold_i, (train_i, test_i) in enumerate(kf.split(range(len(covs)))):\n",
    "        train_X = covs[train_i]\n",
    "        test_X = covs[test_i]    \n",
    "        train_y = y[train_i]    \n",
    "        test_y = y[test_i]    \n",
    "\n",
    "        pipe.fit(train_X, train_y)\n",
    "        probas_train = pipe.predict_proba(train_X)\n",
    "        preds_train = pipe.predict(train_X)\n",
    "        \n",
    "        column_names = [\"id\", \"y_pred\", \"y_true\"]\n",
    "        tmp = pd.DataFrame([len(train_y) * [fold_i], probas_train[:, 1], train_y], index=column_names).T\n",
    "        train_probas = train_probas.append(tmp, ignore_index=True)  \n",
    "        \n",
    "        tmp2 = pd.DataFrame([len(train_y) * [fold_i], preds_train, train_y], index=column_names).T\n",
    "        train_preds = train_preds.append(tmp2, ignore_index=True)  \n",
    "        \n",
    "        probas_test = pipe.predict_proba(test_X)\n",
    "        preds_test = pipe.predict(test_X)\n",
    "\n",
    "        tmp = pd.DataFrame([len(test_y) * [fold_i], probas_test[:, 1], test_y], index=column_names).T\n",
    "        test_probas = test_probas.append(tmp, ignore_index=True)  \n",
    "        \n",
    "        tmp2 = pd.DataFrame([len(test_y) * [fold_i], preds_test, test_y], index=column_names).T\n",
    "        test_preds = test_preds.append(tmp2, ignore_index=True)  \n",
    "        \n",
    "        print(fold_i, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8692932431252803"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_acc(train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8203255335283284"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_acc(test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_preds.to_csv(\"/home/gemeinl/results/all_recs_100_hz/features/riemannian/cv/predictions_train.csv\")\n",
    "test_preds.to_csv(\"/home/gemeinl/results/all_recs_100_hz/features/riemannian/cv/predictions_valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_probas.to_csv(\"/home/gemeinl/results/all_recs_100_hz/features/riemannian/pathological/cv/predictions_train.csv\")\n",
    "test_probas.to_csv(\"/home/gemeinl/results/all_recs_100_hz/features/riemannian/pathological/cv/predictions_valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"C\": C, \"kernel\": kernel, \"adaptation\": adaptation, \"gamma\": \"auto\", \"scaling\": None, \"model\": \"Riemannian\", \"n_features\":21*21, \"n_runs\": n_folds,\n",
    "     \"sfreq\": 100, \"shuffle\": False}\n",
    "with open(\"/home/gemeinl/results/all_recs_100_hz/features/riemannian/pathological/cv/config.json\", \"w\") as json_file:\n",
    "    json.dump(config, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__run final evaluation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_covs_eval = np.load(\"/home/gemeinl/data/covs/mean_eval_covs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval = np.load(\"/home/gemeinl/data/covs/eval_pathology_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((276, 21, 21), 276)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_covs_eval.shape, len(y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"ts\", TimedTransformer(TangentSpace(tsupdate=adaptation, metric=\"riemann\"))),\n",
    "    (\"clf\", SVC(kernel=kernel, C=C, probability=True, gamma=\"auto\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseEstimator.__repr__ of TangentSpace(metric='riemann', tsupdate=False)> fitting time: 12.71s\n",
      "<bound method BaseEstimator.__repr__ of TangentSpace(metric='riemann', tsupdate=False)> transforming time: 0.08s\n",
      "<bound method BaseEstimator.__repr__ of TangentSpace(metric='riemann', tsupdate=False)> transforming time: 0.08s\n",
      "<bound method BaseEstimator.__repr__ of TangentSpace(metric='riemann', tsupdate=False)> transforming time: 0.98s\n",
      "<bound method BaseEstimator.__repr__ of TangentSpace(metric='riemann', tsupdate=False)> transforming time: 0.66s\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(covs, y)\n",
    "preds = pipe.predict(mean_covs_eval)\n",
    "preds_proba = pipe.predict_proba(mean_covs_eval)\n",
    "train_preds = pipe.predict(covs)\n",
    "train_proba = pipe.predict_proba(covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"C\": C, \"kernel\": kernel, \"adaptation\": adaptation, \"gamma\": \"auto\", \"scaling\": None, \"model\": \"Riemannian\", \"n_features\":21*21, \"n_runs\": 1,\n",
    "     \"sfreq\": 100, \"shuffle\": False}\n",
    "with open(\"/home/gemeinl/results/all_recs_100_hz/features/riemannian/pathological/eval/config.json\", \"w\") as json_file:\n",
    "    json.dump(config, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame([train_proba[:, 1], y, len(y) * [0]], index=[\"y_pred\", \"y_true\", \"id\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8696612665684831"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df_train.y_pred >= .5) == df_train.y_true).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame([preds_proba[:, 1], y_eval, len(y_eval) * [0]], index=[\"y_pred\", \"y_true\", \"id\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8586956521739131"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df_eval.y_pred >= .5) == df_eval.y_true).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_train.to_csv(\"/home/gemeinl/results/all_recs_100_hz/features/riemannian/pathological/eval/predictions_train.csv\")\n",
    "df_eval.to_csv(\"/home/gemeinl/results/all_recs_100_hz/features/riemannian/pathological/eval/predictions_eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = pd.read_csv(\"../results/features/riemannian/pathological/cv/predictions_train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8697053406998159\n",
      "0.8729866543948458\n",
      "0.8729866543948458\n",
      "0.8725264611136677\n",
      "0.868844914864243\n"
     ]
    }
   ],
   "source": [
    "for n, g in train_preds.groupby(\"id\"):\n",
    "    print(((g.y_pred >= .5) == g.y_true).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = pd.read_csv(\"../results/features/riemannian/pathological/cv/predictions_valid.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8106617647058824\n",
      "0.8139963167587477\n",
      "0.8139963167587477\n",
      "0.8139963167587477\n",
      "0.8103130755064457\n"
     ]
    }
   ],
   "source": [
    "for n, g in test_preds.groupby(\"id\"):\n",
    "    print(((g.y_pred >= .5) == g.y_true).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125927580977143"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.8106617647058824,\n",
    "0.8139963167587477,\n",
    "0.8139963167587477,\n",
    "0.8139963167587477,\n",
    "0.8103130755064457\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_preds = pd.read_csv(\"../results/features/riemannian/pathological/eval/predictions_eval.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8586956521739131\n"
     ]
    }
   ],
   "source": [
    "for n, g in eval_preds.groupby(\"id\"):\n",
    "    print(((g.y_pred >= .5) == g.y_true).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyriemann",
   "language": "python",
   "name": "pyriemann"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
